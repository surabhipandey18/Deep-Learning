{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13047170,
          "sourceType": "datasetVersion",
          "datasetId": 8261885
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "encoder_decoder",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surabhipandey18/Deep-Learning/blob/main/encoder_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from string import digits\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:44.935553Z",
          "iopub.execute_input": "2025-09-13T13:08:44.93588Z",
          "iopub.status.idle": "2025-09-13T13:08:56.10958Z",
          "shell.execute_reply.started": "2025-09-13T13:08:44.935857Z",
          "shell.execute_reply": "2025-09-13T13:08:56.10896Z"
        },
        "id": "1Hz8gNtLS-0I",
        "outputId": "51fdd903-02d3-48d2-cf08-0bafb1bc9ac4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-09-13 13:08:48.040277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757768928.304554     197 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757768928.384754     197 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Hindi_English_Truncated_Corpus.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:56.36138Z",
          "iopub.execute_input": "2025-09-13T13:08:56.361658Z",
          "iopub.status.idle": "2025-09-13T13:08:57.4471Z",
          "shell.execute_reply.started": "2025-09-13T13:08:56.36161Z",
          "shell.execute_reply": "2025-09-13T13:08:57.446172Z"
        },
        "id": "Cgn_kqcwS-0L",
        "outputId": "1da49d5e-5526-4ed8-c25b-50bb54533184"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      source                                   english_sentence  \\\n0        ted  politicians do not have permission to do what ...   \n1        ted         I'd like to tell you about one such child,   \n2  indic2012  This percentage is even greater than the perce...   \n3        ted  what we really mean is that they're bad at not...   \n4  indic2012  .The ending portion of these Vedas is called U...   \n\n                                      hindi_sentence  \n0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ted</td>\n      <td>politicians do not have permission to do what ...</td>\n      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ted</td>\n      <td>I'd like to tell you about one such child,</td>\n      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indic2012</td>\n      <td>This percentage is even greater than the perce...</td>\n      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ted</td>\n      <td>what we really mean is that they're bad at not...</td>\n      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>indic2012</td>\n      <td>.The ending portion of these Vedas is called U...</td>\n      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lines = df[df['source']=='ted'][['english_sentence', 'hindi_sentence']].dropna().drop_duplicates()\n",
        "lines = lines.sample(n=20000, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:57.448045Z",
          "iopub.execute_input": "2025-09-13T13:08:57.44825Z",
          "iopub.status.idle": "2025-09-13T13:08:57.518102Z",
          "shell.execute_reply.started": "2025-09-13T13:08:57.448233Z",
          "shell.execute_reply": "2025-09-13T13:08:57.517213Z"
        },
        "id": "4ZsDybhUS-0M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#text cleaning\n",
        "def clean_text(text):\n",
        "  exclude = set(string.punctuation)\n",
        "  text = ''.join(ch for ch in text if ch not in exclude)\n",
        "  text = text.translate(str.maketrans('', '', digits))\n",
        "  return text.strip().lower()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:57.5204Z",
          "iopub.execute_input": "2025-09-13T13:08:57.520715Z",
          "iopub.status.idle": "2025-09-13T13:08:57.525547Z",
          "shell.execute_reply.started": "2025-09-13T13:08:57.520691Z",
          "shell.execute_reply": "2025-09-13T13:08:57.524877Z"
        },
        "id": "7G8l2x_TS-0N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lines['english_sentence'] = lines['english_sentence'].apply(clean_text)\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(clean_text)\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'start_ ' + x + ' _end')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:57.526412Z",
          "iopub.execute_input": "2025-09-13T13:08:57.526739Z",
          "iopub.status.idle": "2025-09-13T13:08:57.879598Z",
          "shell.execute_reply.started": "2025-09-13T13:08:57.526712Z",
          "shell.execute_reply": "2025-09-13T13:08:57.878701Z"
        },
        "id": "-i56RPC9S-0O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(lines['english_sentence'])\n",
        "eng_sequence = eng_tokenizer.texts_to_sequences(lines['english_sentence'])\n",
        "\n",
        "hin_tokenizer = Tokenizer(filters='')\n",
        "hin_tokenizer.fit_on_texts(lines['hindi_sentence'])\n",
        "hin_sequence = hin_tokenizer.texts_to_sequences(lines['hindi_sentence'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:57.880515Z",
          "iopub.execute_input": "2025-09-13T13:08:57.88108Z",
          "iopub.status.idle": "2025-09-13T13:08:58.589556Z",
          "shell.execute_reply.started": "2025-09-13T13:08:57.881053Z",
          "shell.execute_reply": "2025-09-13T13:08:58.58894Z"
        },
        "id": "fA2gBfXJS-0P"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "max_eng_len = max([len(seq) for seq in eng_sequence])\n",
        "max_hin_len = max([len(seq) for seq in hin_sequence])\n",
        "\n",
        "encoder_input = pad_sequences(eng_sequence, maxlen=max_eng_len, padding='post')\n",
        "decoder_input = pad_sequences(hin_sequence, maxlen=max_hin_len, padding='post')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:58.590293Z",
          "iopub.execute_input": "2025-09-13T13:08:58.590481Z",
          "iopub.status.idle": "2025-09-13T13:08:58.674283Z",
          "shell.execute_reply.started": "2025-09-13T13:08:58.590466Z",
          "shell.execute_reply": "2025-09-13T13:08:58.673683Z"
        },
        "id": "DG1UECvdS-0Q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder targets\n",
        "decoder_target = np.zeros((decoder_input.shape[0], decoder_input.shape[1],1))\n",
        "decoder_target[:, 0:-1, 0] = decoder_input[:, 1:]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:58.675003Z",
          "iopub.execute_input": "2025-09-13T13:08:58.675183Z",
          "iopub.status.idle": "2025-09-13T13:08:58.682482Z",
          "shell.execute_reply.started": "2025-09-13T13:08:58.675169Z",
          "shell.execute_reply": "2025-09-13T13:08:58.681951Z"
        },
        "id": "7ZWiQVL2S-0Q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#define model Architecture\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
        "latent_dim = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(eng_vocab_size, latent_dim)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding_layer = Embedding(hin_vocab_size, latent_dim)\n",
        "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(hin_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:08:58.683348Z",
          "iopub.execute_input": "2025-09-13T13:08:58.683582Z",
          "iopub.status.idle": "2025-09-13T13:09:01.131264Z",
          "shell.execute_reply.started": "2025-09-13T13:08:58.683557Z",
          "shell.execute_reply": "2025-09-13T13:09:01.130676Z"
        },
        "id": "kiQ7pq8-S-0R",
        "outputId": "3e366480-5db8-4e23-8cb0-1b7ed4b91735"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "I0000 00:00:1757768939.656108     197 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1757768939.656857     197 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#compile and train\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((encoder_input, decoder_input), decoder_target))\n",
        "dataset = dataset.batch(64)\n",
        "model.fit(dataset, epochs=20)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:27:49.548463Z",
          "iopub.execute_input": "2025-09-13T13:27:49.548816Z",
          "iopub.status.idle": "2025-09-13T13:34:52.278183Z",
          "shell.execute_reply.started": "2025-09-13T13:27:49.548789Z",
          "shell.execute_reply": "2025-09-13T13:34:52.277447Z"
        },
        "id": "aSpoY5OCS-0R",
        "outputId": "721a2787-abfd-4c35-8194-bd32f5726bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 65ms/step - accuracy: 0.9167 - loss: 0.3790\nEpoch 2/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.9289 - loss: 0.3352\nEpoch 3/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9364 - loss: 0.3048\nEpoch 4/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9423 - loss: 0.2792\nEpoch 5/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9477 - loss: 0.2567\nEpoch 6/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9513 - loss: 0.2398\nEpoch 7/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9543 - loss: 0.2263\nEpoch 8/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9579 - loss: 0.2093\nEpoch 9/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9609 - loss: 0.1951\nEpoch 10/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9644 - loss: 0.1801\nEpoch 11/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9644 - loss: 0.1779\nEpoch 12/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9701 - loss: 0.1553\nEpoch 13/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9735 - loss: 0.1411\nEpoch 14/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9750 - loss: 0.1338\nEpoch 15/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9762 - loss: 0.1267\nEpoch 16/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9799 - loss: 0.1127\nEpoch 17/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9821 - loss: 0.1021\nEpoch 18/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9843 - loss: 0.0931\nEpoch 19/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9857 - loss: 0.0859\nEpoch 20/20\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9872 - loss: 0.0784\n",
          "output_type": "stream"
        },
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x7b5bd4200ad0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#inference of encoder\n",
        "encoder_model_inf = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "#inference of decoder\n",
        "decoder_state_input_h = Input(shape = (latent_dim,))\n",
        "decoder_state_input_c = Input(shape= (latent_dim, ))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "dec_inf_emb = decoder_embedding_layer(decoder_inputs)\n",
        "dec_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(dec_inf_emb, initial_state=decoder_state_inputs)\n",
        "decoder_outputs_inf = decoder_dense(dec_outputs_inf)\n",
        "decoder_model_inf = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs_inf, state_h_inf, state_c_inf])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:34:57.67715Z",
          "iopub.execute_input": "2025-09-13T13:34:57.67746Z",
          "iopub.status.idle": "2025-09-13T13:34:57.688591Z",
          "shell.execute_reply.started": "2025-09-13T13:34:57.677435Z",
          "shell.execute_reply": "2025-09-13T13:34:57.687838Z"
        },
        "id": "vxz7rVrdS-0S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#reverse lookup\n",
        "reverse_eng = {v: k for k, v in eng_tokenizer.word_index.items()}\n",
        "reverse_hin = {v: k for k, v in hin_tokenizer.word_index.items()}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:35:00.624139Z",
          "iopub.execute_input": "2025-09-13T13:35:00.624939Z",
          "iopub.status.idle": "2025-09-13T13:35:00.633276Z",
          "shell.execute_reply.started": "2025-09-13T13:35:00.624915Z",
          "shell.execute_reply": "2025-09-13T13:35:00.632547Z"
        },
        "id": "U3v_LdZgS-0S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#translate function\n",
        "def translate(sentence):\n",
        "    sentence = clean_text(sentence)\n",
        "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
        "    padded = pad_sequences(seq, maxlen=max_eng_len, padding='post')\n",
        "    states = encoder_model_inf.predict(padded)\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = hin_tokenizer.word_index['start_']\n",
        "\n",
        "    decoded = []\n",
        "    while True:\n",
        "        output, h, c = decoder_model_inf.predict([target_seq] + states)\n",
        "        token_index = np.argmax(output[0, -1, :])\n",
        "        word = reverse_hin.get(token_index, '')\n",
        "\n",
        "        if word == '_end' or len(decoded) >= max_hin_len:\n",
        "            break\n",
        "\n",
        "        decoded.append(word)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = token_index\n",
        "        states = [h, c]\n",
        "\n",
        "    return ' '.join(decoded)\n",
        "\n",
        "print(\"English: And\")\n",
        "print(\"Hindi:\", translate(\"And\"))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-13T13:37:35.433113Z",
          "iopub.execute_input": "2025-09-13T13:37:35.433377Z",
          "iopub.status.idle": "2025-09-13T13:37:35.773126Z",
          "shell.execute_reply.started": "2025-09-13T13:37:35.433361Z",
          "shell.execute_reply": "2025-09-13T13:37:35.772477Z"
        },
        "id": "rvvugdJES-0T",
        "outputId": "920213ac-eaf6-4d6d-ee6d-d8610554a550"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "English: And\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\nHindi: और होता\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "EevYmhq9S-0T"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}